@misc{ujvaryRethinkingSharpnessAwareMinimization2022,
 abstract = {Sharpness-aware minimization (SAM) aims to improve the generalisation of gradient-based learning by seeking out flat minima. In this work, we establish connections between SAM and Mean-Field Variational Inference (MFVI) of neural network parameters. We show that both these methods have interpretations as optimizing notions of flatness, and when using the reparametrisation trick, they both boil down to calculating the gradient at a perturbed version of the current mean parameter. This thinking motivates our study of algorithms that combine or interpolate between SAM and MFVI. We evaluate the proposed variational algorithms on several benchmark datasets, and compare their performance to variants of SAM. Taking a broader perspective, our work suggests that SAM-like updates can be used as a drop-in replacement for the reparametrisation trick.},
 author = {Ujváry, Szilvia and Telek, Zsigmond and Kerekes, Anna and Mészáros, Anna and Huszár, Ferenc},
 date = {2022-10-19},
 eprint = {2210.10452},
 eprintclass = {cs, stat},
 eprinttype = {arXiv},
 file = {/Users/luke/Zotero/storage/YAWC8A8M/Ujváry et al. - 2022 - Rethinking Sharpness-Aware Minimization as Variati.pdf;/Users/luke/Zotero/storage/U6BJHRJR/2210.html},
 keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
 note = {arXiv:2210.10452},
 pubstate = {prepublished},
 title = {Rethinking Sharpness-Aware Minimization as Variational Inference},
 url = {http://arxiv.org/abs/2210.10452},
 urldate = {2024-03-05}
}
