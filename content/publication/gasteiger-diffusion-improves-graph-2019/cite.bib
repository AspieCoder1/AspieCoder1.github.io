@inproceedings{gasteigerDiffusionImprovesGraph2019,
 abstract = {Graph convolution is the core of most Graph Neural Networks (GNNs) and usually approximated by message passing between direct (one-hop) neighbors. In this work, we remove the restriction of using only the direct neighbors by introducing a powerful, yet spatially localized graph convolution: Graph diffusion convolution (GDC). GDC leverages generalized graph diffusion, examples of which are the heat kernel and personalized PageRank. It alleviates the problem of noisy and often arbitrarily defined edges in real graphs. We show that GDC is closely related to spectral-based models and thus combines the strengths of both spatial (message passing) and spectral methods. We demonstrate that replacing message passing with graph diffusion convolution consistently leads to significant performance improvements across a wide range of models on both supervised and unsupervised tasks and a variety of datasets. Furthermore, GDC is not limited to GNNs but can trivially be combined with any graph-based model or algorithm (e.g. spectral clustering) without requiring any changes to the latter or affecting its computational complexity. Our implementation is available online.},
 author = {Gasteiger, Johannes and Weiß enberger, Stefan and Günnemann, Stephan},
 booktitle = {Advances in Neural Information Processing Systems},
 date = {2019},
 eventtitle = {NeurIPS 2019},
 file = {/Users/luke/Zotero/storage/LRTA832S/Gasteiger et al. - 2019 - Diffusion Improves Graph Learning.pdf},
 publisher = {Curran Associates, Inc.},
 title = {Diffusion Improves Graph Learning},
 url = {https://proceedings.neurips.cc/paper_files/paper/2019/hash/23c894276a2c5a16470e6a31f4618d73-Abstract.html},
 urldate = {2023-12-20},
 volume = {32}
}
