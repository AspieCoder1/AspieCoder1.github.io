@misc{smilkovSmoothGradRemovingNoise2017,
 abstract = {Explaining the output of a deep network remains a challenge. In the case of an image classifier, one type of explanation is to identify pixels that strongly influence the final decision. A starting point for this strategy is the gradient of the class score function with respect to the input image. This gradient can be interpreted as a sensitivity map, and there are several techniques that elaborate on this basic idea. This paper makes two contributions: it introduces SmoothGrad, a simple method that can help visually sharpen gradient-based sensitivity maps, and it discusses lessons in the visualization of these maps. We publish the code for our experiments and a website with our results.},
 author = {Smilkov, Daniel and Thorat, Nikhil and Kim, Been and Vi√©gas, Fernanda and Wattenberg, Martin},
 date = {2017-06-12},
 eprint = {1706.03825},
 eprintclass = {cs, stat},
 eprinttype = {arXiv},
 file = {/Users/luke/Zotero/storage/7DV8VPQB/Smilkov et al. - 2017 - SmoothGrad removing noise by adding noise.pdf;/Users/luke/Zotero/storage/7W4R8KDR/1706.html},
 keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning},
 note = {arXiv:1706.03825},
 pubstate = {prepublished},
 shorttitle = {SmoothGrad},
 title = {SmoothGrad: removing noise by adding noise},
 url = {http://arxiv.org/abs/1706.03825},
 urldate = {2024-03-08}
}
