@misc{wangDeepGraphLibrary2020,
 abstract = {Advancing research in the emerging field of deep graph learning requires new tools to support tensor computation over graphs. In this paper, we present the design principles and implementation of Deep Graph Library (DGL). DGL distills the computational patterns of GNNs into a few generalized sparse tensor operations suitable for extensive parallelization. By advocating graph as the central programming abstraction, DGL can perform optimizations transparently. By cautiously adopting a framework-neutral design, DGL allows users to easily port and leverage the existing components across multiple deep learning frameworks. Our evaluation shows that DGL significantly outperforms other popular GNN-oriented frameworks in both speed and memory consumption over a variety of benchmarks and has little overhead for small scale workloads.},
 author = {Wang, Minjie and Zheng, Da and Ye, Zihao and Gan, Quan and Li, Mufei and Song, Xiang and Zhou, Jinjing and Ma, Chao and Yu, Lingfan and Gai, Yu and Xiao, Tianjun and He, Tong and Karypis, George and Li, Jinyang and Zhang, Zheng},
 date = {2020-08-25},
 eprint = {1909.01315},
 eprintclass = {cs.LG},
 eprinttype = {arXiv},
 file = {/Users/luke/Zotero/storage/BDV2NLYL/Wang et al. - 2020 - Deep Graph Library A Graph-Centric, Highly-Perfor.pdf;/Users/luke/Zotero/storage/TPHZGYU7/1909.html},
 keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
 note = {arXiv:1909.01315},
 pubstate = {prepublished},
 shorttitle = {Deep Graph Library},
 title = {Deep Graph Library: A Graph-Centric, Highly-Performant Package for Graph Neural Networks},
 url = {http://arxiv.org/abs/1909.01315},
 urldate = {2023-12-20}
}
