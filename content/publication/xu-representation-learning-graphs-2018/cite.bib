@inproceedings{xuRepresentationLearningGraphs2018,
 abstract = {Recent deep learning approaches for representation learning on graphs follow a neighborhood aggregation procedure. We analyze some important properties of these models, and propose a strategy to overcome those. In particular, the range of "neighboring" nodes that a node’s representation draws from strongly depends on the graph structure, analogous to the spread of a random walk. To adapt to local neighborhood properties and tasks, we explore an architecture – jumping knowledge (JK) networks – that flexibly leverages, for each node, different neighborhood ranges to enable better structure-aware representation. In a number of experiments on social, bioinformatics and citation networks, we demonstrate that our model achieves state-of-the-art performance. Furthermore, combining the JK framework with models like Graph Convolutional Networks, GraphSAGE and Graph Attention Networks consistently improves those models’ performance.},
 author = {Xu, Keyulu and Li, Chengtao and Tian, Yonglong and Sonobe, Tomohiro and Kawarabayashi, Ken-ichi and Jegelka, Stefanie},
 booktitle = {Proceedings of the 35th International Conference on Machine Learning},
 date = {2018-07-03},
 eventtitle = {International Conference on Machine Learning},
 file = {/Users/luke/Zotero/storage/7KBA754S/Xu et al. - 2018 - Representation Learning on Graphs with Jumping Kno.pdf;/Users/luke/Zotero/storage/XP98BJ8B/Xu et al. - 2018 - Representation Learning on Graphs with Jumping Kno.pdf},
 issn = {2640-3498},
 langid = {english},
 pages = {5453--5462},
 publisher = {PMLR},
 title = {Representation Learning on Graphs with Jumping Knowledge Networks},
 url = {https://proceedings.mlr.press/v80/xu18c.html},
 urldate = {2024-08-12}
}
