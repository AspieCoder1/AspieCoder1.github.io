@misc{zhangLearnableHypergraphLaplacian2021,
 abstract = {HyperGraph Convolutional Neural Networks (HGCNNs) have demonstrated their potential in modeling high-order relations preserved in graph structured data. However, most existing convolution filters are localized and determined by the pre-defined initial hypergraph topology, neglecting to explore implicit and long-ange relations in real-world data. In this paper, we propose the first learning-based method tailored for constructing adaptive hypergraph structure, termed HypERgrAph Laplacian aDaptor (HERALD), which serves as a generic plug-in-play module for improving the representational power of HGCNNs. Specifically, HERALD adaptively optimizes the adjacency relationship between hypernodes and hyperedges in an end-to-end manner and thus the task-aware hypergraph is learned. Furthermore, HERALD employs the self-attention mechanism to capture the non-local paired-nodes relation. Extensive experiments on various popular hypergraph datasets for node classification and graph classification tasks demonstrate that our approach obtains consistent and considerable performance enhancement, proving its effectiveness and generalization ability.},
 author = {Zhang, Jiying and Chen, Yuzhao and Xiao, Xi and Lu, Runiu and Xia, Shu-Tao},
 date = {2021-06-10},
 eprint = {2106.05701},
 eprintclass = {cs.LG},
 eprinttype = {arXiv},
 file = {/Users/luke/Zotero/storage/VIASVDM7/Zhang et al. - 2021 - Learnable Hypergraph Laplacian for Hypergraph Lear.pdf;/Users/luke/Zotero/storage/4EKVYN5A/2106.html},
 keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning},
 note = {arXiv:2106.05701},
 pubstate = {prepublished},
 title = {Learnable Hypergraph Laplacian for Hypergraph Learning},
 url = {http://arxiv.org/abs/2106.05701},
 urldate = {2024-02-26}
}
