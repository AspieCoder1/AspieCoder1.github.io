---
title: Explainability Methods for Graph Convolutional Neural Networks
authors:
- Phillip E. Pope
- Soheil Kolouri
- Mohammad Rostami
- Charles E. Martin
- Heiko Hoffmann
date: '2019-06-01'
publishDate: '2024-09-13T09:52:59.026071Z'
publication_types:
- paper-conference
publication: '*2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition
  (CVPR)*'
abstract: 'With the growing use of graph convolutional neural networks (GCNNs) comes
  the need for explainability. In this paper, we introduce explainability methods
  for GCNNs. We develop the graph analogues of three prominent explainability methods
  for convolutional neural networks: contrastive gradient-based (CG) saliency maps,
  Class Activation Mapping (CAM), and Excitation Back-Propagation (EB) and their variants,
  gradient-weighted CAM (Grad-CAM) and contrastive EB (c-EB). We show a proof-of-concept
  of these methods on classification problems in two application domains: visual scene
  graphs and molecular graphs. To compare the methods, we identify three desirable
  properties of explanations: (1) their importance to classification, as measured
  by the impact of occlusions, (2) their contrastivity with respect to different classes,
  and (3) their sparseness on a graph. We call the corresponding quantitative metrics
  fidelity, contrastivity, and sparsity and evaluate them for each method. Lastly,
  we analyze the salient subgraphs obtained from explanations and report frequently
  occurring patterns.'
tags:
- Deep Learning
links:
- name: URL
  url: https://ieeexplore.ieee.org/document/8954227
---
