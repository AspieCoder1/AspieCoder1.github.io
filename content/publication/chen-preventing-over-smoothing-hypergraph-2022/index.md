---
title: Preventing Over-Smoothing for Hypergraph Neural Networks
authors:
- Guanzi Chen
- Jiying Zhang
- Xi Xiao
- Yang Li
date: '2022-11-02'
publishDate: '2024-09-13T09:52:57.948354Z'
publication_types:
- manuscript
abstract: In recent years, hypergraph learning has attracted great attention due to
  its capacity in representing complex and high-order relationships. However, current
  neural network approaches designed for hypergraphs are mostly shallow, thus limiting
  their ability to extract information from high-order neighbors. In this paper, we
  show both theoretically and empirically, that the performance of hypergraph neural
  networks does not improve as the number of layers increases, which is known as the
  over-smoothing problem. To avoid this issue, we develop a new deep hypergraph convolutional
  network called Deep-HGCN, which can maintain the heterogeneity of node representation
  in deep layers. Specifically, we prove that a $k$-layer Deep-HGCN simulates a polynomial
  filter of order $k$ with arbitrary coefficients, which can relieve the problem of
  over-smoothing. Experimental results on various datasets demonstrate the superior
  performance of the proposed model compared to the state-of-the-art hypergraph learning
  approaches.
tags:
- Computer Science - Machine Learning
links:
- name: URL
  url: http://arxiv.org/abs/2203.17159
---
