@article{yuanInterpretingImageClassifiers2022,
 abstract = {Deep models are commonly treated as black-boxes and lack interpretability. Here, we propose a novel approach to interpret deep image classifiers by generating discrete masks. Our method follows the generative adversarial network formalism. The deep model to be interpreted is the discriminator while we train a generator to explain it. The generator is trained to capture discriminative image regions that should convey the same or similar meaning as the original image from the modelâ€™s perspective. It produces a probability map from which a discrete mask can be sampled. Then the discriminator is used to measure the quality of the sampled mask and provide feedbacks for updating. Due to the sampling operations, the generator cannot be trained directly by back-propagation. We propose to update it using policy gradient. Furthermore, we propose to incorporate gradients as auxiliary information to reduce the search space and facilitate training. We conduct both quantitative and qualitative experiments on the ILSVRC dataset. Experimental results indicate that our method can provide reasonable explanations for predictions and outperform existing approaches. In addition, our method can pass the model randomization test, indicating that it is reasoning the attribution of network predictions.},
 author = {Yuan, Hao and Cai, Lei and Hu, Xia and Wang, Jie and Ji, Shuiwang},
 date = {2022-04-01},
 issn = {0162-8828},
 journaltitle = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
 langid = {english},
 number = {04},
 pages = {2019--2030},
 publisher = {IEEE Computer Society},
 title = {Interpreting Image Classifiers by Generating Discrete Masks},
 url = {https://www.computer.org/csdl/journal/tp/2022/04/09214476/1nHNEVsfYTm},
 urldate = {2024-03-08},
 volume = {44}
}
