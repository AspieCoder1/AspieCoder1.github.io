@inproceedings{hamiltonInductiveRepresentationLearning2017,
 abstract = {Low-dimensional embeddings of nodes in large graphs have proved extremely useful in a variety of prediction tasks, from content recommendation to identifying protein functions. However, most existing approaches require that all nodes in the graph are present during training of the embeddings; these previous approaches are inherently transductive and do not naturally generalize to unseen nodes. Here we present GraphSAGE, a general, inductive framework that leverages node feature information (e.g., text attributes) to efficiently generate node embeddings.  Instead of training individual embeddings for each node, we learn a function that generates embeddings by sampling and aggregating features from a node's local neighborhood. Our algorithm outperforms strong baselines on three inductive node-classification benchmarks: we classify the category of unseen nodes in evolving information graphs based on citation and Reddit post data, and we show that our algorithm generalizes to completely unseen graphs using a multi-graph dataset of protein-protein interactions.},
 author = {Hamilton, Will and Ying, Zhitao and Leskovec, Jure},
 booktitle = {Advances in Neural Information Processing Systems},
 date = {2017},
 eventtitle = {NIPS 2017},
 file = {/Users/luke/Zotero/storage/S8CGCTG9/Hamilton et al. - 2017 - Inductive Representation Learning on Large Graphs.pdf},
 publisher = {Curran Associates, Inc.},
 title = {Inductive Representation Learning on Large Graphs},
 url = {https://proceedings.neurips.cc/paper_files/paper/2017/hash/5dd9db5e033da9c6fb5ba83c7a7ebea9-Abstract.html},
 urldate = {2024-01-26},
 volume = {30}
}
