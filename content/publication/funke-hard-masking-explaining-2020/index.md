---
title: Hard Masking for Explaining Graph Neural Networks
authors:
- Thorben Funke
- Megha Khosla
- Avishek Anand
date: '2020-10-02'
publishDate: '2024-09-13T09:52:58.233933Z'
publication_types:
- article-journal
abstract: Graph Neural Networks (GNNs) are a flexible and powerful family of models
  that build nodes' representations on irregular graph-structured data. This paper
  focuses on explaining or interpreting the rationale underlying a given prediction
  of already trained graph neural networks for the node classification task. Existing
  approaches for interpreting GNNs try to find subsets of important features and nodes
  by learning a continuous mask. Our objective is to find discrete masks that are
  arguably more interpretable while minimizing the expected deviation from the underlying
  model's prediction. We empirically show that our explanations are both more predictive
  and sparse. Additionally, we find that multiple diverse explanations are possible,
  which sufficiently explain a prediction. Finally, we analyze the explanations to
  find the effect of network homophily on the decision-making process of GNNs.
links:
- name: URL
  url: https://openreview.net/forum?id=uDN8pRAdsoC
---
