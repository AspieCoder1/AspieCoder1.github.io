---
title: 'GraphLIME: Local Interpretable Model Explanations for Graph Neural Networks'
authors:
- Qiang Huang
- Makoto Yamada
- Yuan Tian
- Dinesh Singh
- Yi Chang
date: '2023-07-01'
publishDate: '2024-09-13T09:52:58.537405Z'
publication_types:
- article-journal
abstract: Recently, graph neural networks (GNN) were shown to be successful in effectively
  representing graph structured data because of their good performance and generalization
  ability. However, explaining the effectiveness of GNN models is a challenging task
  because of the complex nonlinear transformations made over the iterations. In this
  paper, we propose GraphLIME, a local interpretable model explanation for graphs
  using the Hilbert-Schmidt Independence Criterion (HSIC) Lasso, which is a nonlinear
  feature selection method. GraphLIME is a generic GNN-model explanation framework
  that learns a nonlinear interpretable model locally in the subgraph of the node
  being explained. Through experiments on two real-world datasets, the explanations
  of GraphLIME are found to be of extraordinary degree and more descriptive in comparison
  to the existing explanation methods.
links:
- name: URL
  url: https://doi.org/10.1109/TKDE.2022.3187455
---
