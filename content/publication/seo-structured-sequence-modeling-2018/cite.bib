@inproceedings{seoStructuredSequenceModeling2018,
 abstract = {This paper introduces Graph Convolutional Recurrent Network (GCRN), a deep learning model able to predict structured sequences of data. Precisely, GCRN is a generalization of classical recurrent neural networks (RNN) to data structured by an arbitrary graph. The structured sequences can represent series of frames in videos, spatio-temporal measurements on a network of sensors, or random walks on a vocabulary graph for natural language modeling. The proposed model combines convolutional neural networks (CNN) on graphs to identify spatial structures and RNN to find dynamic patterns. We study two possible architectures of GCRN, and apply the models to two practical problems: predicting moving MNIST data, and modeling natural language with the Penn Treebank dataset. Experiments show that exploiting simultaneously graph spatial and dynamic information about data can improve both precision and learning speed.},
 author = {Seo, Youngjoo and Defferrard, MichaÃ«l and Vandergheynst, Pierre and Bresson, Xavier},
 booktitle = {Neural Information Processing},
 date = {2018},
 editor = {Cheng, Long and Leung, Andrew Chi Sing and Ozawa, Seiichi},
 file = {/Users/luke/Zotero/storage/DTJBGN8V/Seo et al. - 2018 - Structured Sequence Modeling with Graph Convolutio.pdf},
 isbn = {978-3-030-04167-0},
 keywords = {Graph neural networks,Language modeling,Recurrent neural networks},
 langid = {english},
 location = {Cham},
 pages = {362--373},
 publisher = {Springer International Publishing},
 series = {Lecture Notes in Computer Science},
 title = {Structured Sequence Modeling with Graph Convolutional Recurrent Networks}
}
