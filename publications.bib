@misc{braithwaiteHeterogeneousSheafNeural2024,
  title       = {Heterogeneous {{Sheaf Neural Networks}}},
  author      = {Braithwaite, Luke and Duta, Iulia and Liò, Pietro},
  date        = {2024-09-12},
  eprint      = {2409.08036},
  eprinttype  = {arXiv},
  eprintclass = {cs.LG},
  url         = {http://arxiv.org/abs/2409.08036},
  urldate     = {2024-09-13},
  abstract    = {Heterogeneous graphs, with nodes and edges of different types, are commonly used to model relational structures in many real-world applications. Standard Graph Neural Networks (GNNs) struggle to process heterogeneous data due to oversmoothing. Instead, current approaches have focused on accounting for the heterogeneity in the model architecture, leading to increasingly complex models. Inspired by recent work, we propose using cellular sheaves to model the heterogeneity in the graph's underlying topology. Instead of modelling the data as a graph, we represent it as cellular sheaves, which allows us to encode the different data types directly in the data structure, eliminating the need to inject them into the architecture. We introduce HetSheaf, a general framework for heterogeneous sheaf neural networks, and a series of heterogeneous sheaf predictors to better encode the data's heterogeneity into the sheaf structure. Finally, we empirically evaluate HetSheaf on several standard heterogeneous graph benchmarks, achieving competitive results whilst being more parameter-efficient.},
  pubstate    = {prepublished},
  keywords    = {Computer Science - Machine Learning},
  file        = {/Users/luke/Zotero/storage/JRLBYAGG/Braithwaite et al. - 2024 - Heterogeneous Sheaf Neural Networks.pdf;/Users/luke/Zotero/storage/WZSWDN87/2409.html},
  note        = {arXiv:2409.08036}
}

@misc{wangTopoteinTopologicalDeep2025,
  title = {Topotein: {{Topological Deep Learning}} for {{Protein Representation Learning}}},
  shorttitle = {Topotein},
  author = {Wang, Zhiyu and Jamasb, Arian and Hajij, Mustafa and Morehead, Alex and Braithwaite, Luke and Liò, Pietro},
  date = {2025-09-04},
  eprint = {2509.03885},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2509.03885},
  urldate = {2025-09-05},
  abstract = {Protein representation learning (PRL) is crucial for understanding structure-function relationships, yet current sequence- and graph-based methods fail to capture the hierarchical organization inherent in protein structures. We introduce Topotein, a comprehensive framework that applies topological deep learning to PRL through the novel Protein Combinatorial Complex (PCC) and Topology-Complete Perceptron Network (TCPNet). Our PCC represents proteins at multiple hierarchical levels -- from residues to secondary structures to complete proteins -- while preserving geometric information at each level. TCPNet employs SE(3)-equivariant message passing across these hierarchical structures, enabling more effective capture of multi-scale structural patterns. Through extensive experiments on four PRL tasks, TCPNet consistently outperforms state-of-the-art geometric graph neural networks. Our approach demonstrates particular strength in tasks such as fold classification which require understanding of secondary structure arrangements, validating the importance of hierarchical topological features for protein analysis.},
  pubstate = {prepublished},
  keywords = {Computer Science - Machine Learning},
  file = {/Users/luke/Zotero/storage/KSB49NF4/Wang et al. - 2025 - Topotein Topological Deep Learning for Protein Representation Learning.pdf;/Users/luke/Zotero/storage/R47LFJZ2/2509.html}
}
